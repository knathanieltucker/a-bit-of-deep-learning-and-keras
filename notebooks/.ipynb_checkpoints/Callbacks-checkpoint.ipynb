{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of callbacks\n",
    "\n",
    "A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Callbacks\n",
    "\n",
    "There are a couple of callbacks that you are already using without knowing it:\n",
    "\n",
    "* BaseLogger: Callback that accumulates epoch averages of metrics.\n",
    "* ProgbarLogger: Callback that prints metrics to stdout.\n",
    "* History: Callback that records events into a History object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even More Callbacks\n",
    "\n",
    "I'll show off a set of callbacks available to you to use with any model, and then we will talk about custom callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    filepath='tmp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='max',\n",
    "    period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.01,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "lrs = LearningRateScheduler(lambda x: 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "rlrop = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1, \n",
    "    patience=10, \n",
    "    verbose=0, \n",
    "    mode='auto', \n",
    "    epsilon=0.0001, \n",
    "    cooldown=4, \n",
    "    min_lr=10e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csvl = CSVLogger(\n",
    "    filename='tmp/training.log',\n",
    "    separator=',', \n",
    "    append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.TensorBoard at 0x112630110>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "TensorBoard(\n",
    "    log_dir='./logs', \n",
    "    histogram_freq=0, \n",
    "    write_graph=True, \n",
    "    write_images=False,\n",
    "    embeddings_freq=100,\n",
    "    embeddings_layer_names=None, # this list of embedding layers...\n",
    "    embeddings_metadata=None)      # with this metadata associated with them.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Callback\n",
    "\n",
    "If that was not enough for you, here is the big one. \n",
    "\n",
    "This callback is constructed with anonymous functions that will be called at the appropriate time. Note that the callbacks expects positional arguments, as: - on_epoch_begin and on_epoch_end expect two positional arguments: epoch, logs - on_batch_begin and on_batch_end expect two positional arguments: batch, logs - on_train_begin and on_train_end expect one positional argument: logs\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "* on_epoch_begin: called at the beginning of every epoch.\n",
    "* on_epoch_end: called at the end of every epoch.\n",
    "* on_batch_begin: called at the beginning of every batch.\n",
    "* on_batch_end: called at the end of every batch.\n",
    "* on_train_begin: called at the beginning of model training.\n",
    "* on_train_end: called at the end of model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "# Print the batch number at the beginning of every batch.\n",
    "def print_batch(batch, logs):\n",
    "    print batch\n",
    "batch_print_callback = LambdaCallback(\n",
    "    on_batch_begin=print_batch)\n",
    "\n",
    "# Terminate some processes after having finished model training.\n",
    "processes = []\n",
    "cleanup_callback = LambdaCallback(\n",
    "    on_train_end=lambda logs: [\n",
    "    p.terminate() for p in processes if p.is_alive()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Custom Callbacks\n",
    "\n",
    "You can create a custom callback by extending the base class keras.callbacks.Callback. A callback has access to its associated model through the class property self.model.\n",
    "\n",
    "Abstract base class used to build new callbacks.\n",
    "\n",
    "#### Properties\n",
    "\n",
    "* params: dict. Training parameters (eg. verbosity, batch size, number of epochs...).\n",
    "* model: instance of keras.models.Model. Reference of the model being trained.\n",
    "\n",
    "The logs dictionary that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch.\n",
    "\n",
    "Currently, the .fit() method of the Sequential model class will include the following quantities in the logs that it passes to its callbacks:\n",
    "\n",
    "* on_epoch_end: logs include acc and loss, and optionally include val_loss (if validation is enabled in fit), and val_acc (if validation and accuracy monitoring are enabled).\n",
    "* on_batch_begin: logs include size, the number of samples in the current batch.\n",
    "* on_batch_end: logs include loss, and optionally acc (if accuracy monitoring is enabled).\n",
    "\n",
    "Here's a simple example saving a list of losses over each batch during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

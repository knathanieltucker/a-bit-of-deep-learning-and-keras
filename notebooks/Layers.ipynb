{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Keras layers\n",
    "\n",
    "All Keras layers have a number of methods in common:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Input\n",
    "\n",
    "inputs = Input((8,))\n",
    "layer = Dense(8)\n",
    "\n",
    "layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dense'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.37464097, -0.27893341,  0.49695486,  0.4449653 ,  0.36643338,\n",
       "         -0.52931106, -0.46890604, -0.45965397],\n",
       "        [-0.40730417, -0.18583602,  0.37762654,  0.11463147,  0.28971136,\n",
       "          0.57164758, -0.15994304,  0.32945877],\n",
       "        [ 0.36391342,  0.14205736, -0.10808742, -0.4931342 ,  0.0342685 ,\n",
       "          0.14510453, -0.23283812, -0.33516946],\n",
       "        [-0.287334  , -0.13771147,  0.39885491, -0.13430265, -0.30147257,\n",
       "         -0.46581769, -0.27736709,  0.57230049],\n",
       "        [ 0.00393558,  0.27578139,  0.13987607,  0.35666347, -0.46667796,\n",
       "         -0.05191928,  0.52654058,  0.44505733],\n",
       "        [ 0.35879415, -0.42859054, -0.35855487,  0.17172635,  0.28866434,\n",
       "          0.19636095, -0.11876026, -0.41038626],\n",
       "        [-0.30232173,  0.24163556, -0.01312065, -0.18224221,  0.06398374,\n",
       "          0.59276479, -0.04110891,  0.38710332],\n",
       "        [ 0.38055694, -0.18147221,  0.1881265 ,  0.27507681,  0.35192412,\n",
       "         -0.27093357,  0.18050861,  0.35254461]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_bias = np.array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])\n",
    "layer.set_weights([layer.get_weights()[0], new_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.37464097, -0.27893341,  0.49695486,  0.4449653 ,  0.36643338,\n",
       "         -0.52931106, -0.46890604, -0.45965397],\n",
       "        [-0.40730417, -0.18583602,  0.37762654,  0.11463147,  0.28971136,\n",
       "          0.57164758, -0.15994304,  0.32945877],\n",
       "        [ 0.36391342,  0.14205736, -0.10808742, -0.4931342 ,  0.0342685 ,\n",
       "          0.14510453, -0.23283812, -0.33516946],\n",
       "        [-0.287334  , -0.13771147,  0.39885491, -0.13430265, -0.30147257,\n",
       "         -0.46581769, -0.27736709,  0.57230049],\n",
       "        [ 0.00393558,  0.27578139,  0.13987607,  0.35666347, -0.46667796,\n",
       "         -0.05191928,  0.52654058,  0.44505733],\n",
       "        [ 0.35879415, -0.42859054, -0.35855487,  0.17172635,  0.28866434,\n",
       "          0.19636095, -0.11876026, -0.41038626],\n",
       "        [-0.30232173,  0.24163556, -0.01312065, -0.18224221,  0.06398374,\n",
       "          0.59276479, -0.04110891,  0.38710332],\n",
       "        [ 0.38055694, -0.18147221,  0.1881265 ,  0.27507681,  0.35192412,\n",
       "         -0.27093357,  0.18050861,  0.35254461]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'input_1:0' shape=(?, 8) dtype=float32>,\n",
       " <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 8) dtype=float32>,\n",
       " (None, 8),\n",
       " (None, 8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.input, layer.output, layer.input_shape, layer.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer dense_1 has multiple inbound nodes, hence the notion of \"layer input\" is ill-defined. Use `get_input_at(node_index)` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b365fab97f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nate/Desktop/keras-tutorial/env/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             raise AttributeError('Layer ' + self.name +\n\u001b[0;32m--> 883\u001b[0;31m                                  \u001b[0;34m' has multiple inbound nodes, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m                                  \u001b[0;34m'hence the notion of \"layer input\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                                  \u001b[0;34m'is ill-defined. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer dense_1 has multiple inbound nodes, hence the notion of \"layer input\" is ill-defined. Use `get_input_at(node_index)` instead."
     ]
    }
   ],
   "source": [
    "layer.input, layer.output, layer.input_shape, layer.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'input_1:0' shape=(?, 8) dtype=float32>,\n",
       " <tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 8) dtype=float32>,\n",
       " (None, 8),\n",
       " (None, 8))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_input_at(0), layer.get_output_at(0), layer.get_input_shape_at(0), layer.get_output_shape_at(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Individual Layer Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'linear',\n",
       " 'activity_regularizer': None,\n",
       " 'bias_constraint': None,\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'bias_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'distribution': 'uniform',\n",
       "   'mode': 'fan_avg',\n",
       "   'scale': 1.0,\n",
       "   'seed': None}},\n",
       " 'kernel_regularizer': None,\n",
       " 'name': 'dense_3',\n",
       " 'trainable': True,\n",
       " 'units': 32,\n",
       " 'use_bias': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = Dense(32)\n",
    "config = layer.get_config()\n",
    "reconstructed_layer = Dense.from_config(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "config = layer.get_config()\n",
    "layer = layers.deserialize({'class_name': layer.__class__.__name__,\n",
    "                            'config': config})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Method\n",
    "\n",
    "The lambda method allows you to make any stateless transformation (available in our backend which is tensorflow) to our tensors. Including transformation logic outside a layer will mess up any model, so make sure to put it inside a lambda layer.\n",
    "\n",
    "The output shape is not necessary in tensorflow as it will try to impute it. That being said, for some complex functions it might be better to specify it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Lambda at 0x1132a70d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "Lambda(lambda x: x ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Lambda at 0x1131b0c10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def antirectifier(x):\n",
    "    x -= K.mean(x, axis=1, keepdims=True)\n",
    "    x = K.l2_normalize(x, axis=1)\n",
    "    pos = K.relu(x)\n",
    "    neg = K.relu(-x)\n",
    "    return K.concatenate([pos, neg], axis=1)\n",
    "\n",
    "def antirectifier_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 2  # only valid for 2D tensors\n",
    "    shape[-1] *= 2\n",
    "    return tuple(shape)\n",
    "\n",
    "Lambda(antirectifier, output_shape=antirectifier_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Lambda at 0x1132a7b10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "Lambda(tf.reduce_mean, output_shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Lambda at 0x1132a7dd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_pow(x, po=2):\n",
    "    return x ** po\n",
    "\n",
    "Lambda(to_pow, arguments={'po':5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing your own Keras layers\n",
    "\n",
    "For simple, stateless custom operations, you are probably better off using layers.core.Lambda layers. But for any custom operation that has trainable weights, you should implement your own layer.\n",
    "\n",
    "Here is the skeleton of a Keras layer, as of Keras 2.0 (if you have an older version, please upgrade). There are only three methods you need to implement:\n",
    "\n",
    "* build(input_shape): this is where you will define your weights. This method must set self.built = True, which can be done by calling super([Layer], self).build().\n",
    "* call(x): this is where the layer's logic lives. Unless you want your layer to support masking, you only have to care about the first argument passed to call: the input tensor.\n",
    "* compute_output_shape(input_shape): in case your layer modifies the shape of its input, you should specify here the shape transformation logic. This allows Keras to do automatic shape inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.dot(x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
